# Day 1: Repository Setup and Initial Data Loading/Summarization

### Overview
Today was the start of my adventure using GitHub and JupyterLab for my sentiment analysis project. I spent the day setting up my repository, diving into data, and getting the hang of version control. Here’s a rundown of what I accomplished, the bumps I hit along the way, and some key things I learned on day one.

### Setting Up the Repository
First things first, I created a new GitHub repository to keep everything organized and ensure I’m on top of version control. I initialized the repository and got it set up for my project. After making some initial tweaks, I committed my changes and pushed them to GitHub. It felt great knowing I could access my work at any time from both of my devices and maintain a proper version control.

### Data Loading and Summarization
Next up was loading my data and summarizing it. I imported my dataset into a Jupyter notebook to start the analysis and wrote a function that takes a dataframe and gives a summary of the key points. This helped me spot potential issues in the data, like missing values or odd distributions. However, I ran into a small problem. Some of the column headers were either missing or not labeled correctly, so I had to manually add those names to get everything in order.

### Challenges Faced
The biggest hurdle today was definitely dealing with those missing column headers. Manually fixing this made me realize how crucial it is to check data quality before diving into analysis. Additionally, getting the hang of git was a quick hurdle that felt equally rewarding.

### Key Learnings
Today was full of learning moments. I discovered the value of writing reusable code, which saves me time and keeps things consistent. I also got a better grip on using GitHub to manage branches and track my projects, which will be super helpful when collaborating with others. Additionally, taking the time to write clear documentation is essential. It makes understanding my code easier for me and anyone else who might look at it later.

### Next Steps
Looking ahead, I plan to pre-process the data and conduct exploratory data analysis in preparation for modeling. I look forward to gaining insights and expanding my understanding throughout this process.

### Conclusion
Overall, day one was a productive launch into my sentiment analysis project using GitHub and JupyterLab. I was able to fix small errors and summarize the data, which helped me gain a deeper understanding of what I’m working with. The challenges I faced offered valuable insights, and I look forward to building on this foundation.